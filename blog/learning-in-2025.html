<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Things I want to learn in 2025 - My Site</title>
    <link rel="stylesheet" href="/static/style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap"
      rel="stylesheet"
    />
        <script src="../static/script.js"></script>
    <!-- 100% privacy-first analytics -->
<script data-collect-dnt="true" async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
</script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6MR2H8YX5K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6MR2H8YX5K');
</script>
  </head>
  <body>
    <div class="terminal">
      <div class="menubar">
        <ul>
          <li><a href="/" data-nav="home">Home</a></li>
          <li><a href="/blog/" data-nav="blog">Blog</a></li>
          <li>
            <a href="/projects/" data-nav="projects">Projects</a>
          </li>
          <li>
            <a href="/contact/" data-nav="contact">Contact</a>
          </li>
        </ul>
      </div>
      <main>
        <div class="page-content"><h1
id="things-i-want-to-learn-in-2025">Things I want to learn in 2025</h1>
<h2 id="books">Books</h2>
<ol type="1">
<li><em>Profiles of the Future</em><span class="citation"
data-cites="clarke2013profiles"><sup><a href="#ref-clarke2013profiles"
role="doc-biblioref">1</a></sup></span></li>
<li>Art of Doing Science and Engineering: Learning to Learn<span
class="citation" data-cites="hamming1997art"><sup><a
href="#ref-hamming1997art" role="doc-biblioref">3</a></sup></span></li>
<li><em>Code: The Hidden Language of Computer Hardware and
Software</em><span class="citation" data-cites="petzold2000code"><sup><a
href="#ref-petzold2000code" role="doc-biblioref">4</a></sup></span></li>
<li>But How Do It Know?: The Basic Principles of Computers for
Everyone<span class="citation" data-cites="scott2009but"><sup><a
href="#ref-scott2009but" role="doc-biblioref">7</a></sup></span></li>
<li>Life 3.0: Being Human in the Age of Artificial Intelligence<span
class="citation" data-cites="tegmark2018life"><sup><a
href="#ref-tegmark2018life"
role="doc-biblioref">31</a></sup></span></li>
<li>Human Compatible: AI and the Problem of Control<span
class="citation" data-cites="russell2019human"><sup><a
href="#ref-russell2019human"
role="doc-biblioref">34</a></sup></span></li>
<li><em>Artificial Intelligence: From Medieval Robots to Neural
Networks</em><span class="citation"
data-cites="pickover2019artificial"><sup><a
href="#ref-pickover2019artificial"
role="doc-biblioref">37</a></sup></span></li>
<li>A New History of Modern Computing<span class="citation"
data-cites="haigh2021new"><sup><a href="#ref-haigh2021new"
role="doc-biblioref">46</a></sup></span></li>
<li>The Alignment Problem: How Can Machines Learn Human Values?<span
class="citation" data-cites="christian2021alignment"><sup><a
href="#ref-christian2021alignment"
role="doc-biblioref">47</a></sup></span></li>
<li>The Elements of Computing Systems: Building a Modern Computer from
First Principles<span class="citation"
data-cites="nisan2021elements"><sup><a href="#ref-nisan2021elements"
role="doc-biblioref">48</a></sup></span></li>
<li>How we learn: Why brains learn better than any machine… for now<span
class="citation" data-cites="dehaene2021we"><sup><a
href="#ref-dehaene2021we" role="doc-biblioref">45</a></sup></span></li>
<li>The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn
of AI<span class="citation" data-cites="li2023worlds"><sup><a
href="#ref-li2023worlds" role="doc-biblioref">61</a></sup></span></li>
<li>The Singularity Is Nearer: When We Merge with AI<span
class="citation" data-cites="kurzweil2024singularity"><sup><a
href="#ref-kurzweil2024singularity"
role="doc-biblioref">67</a></sup></span></li>
<li><em>Paths, Dangers, Strategies</em><span class="citation"
data-cites="bostrom2014paths"><sup><a href="#ref-bostrom2014paths"
role="doc-biblioref">14</a></sup></span></li>
</ol>
<h2 id="textbooks">Textbooks</h2>
<ol type="1">
<li>Introduction to Information Retrieval<span class="citation"
data-cites="schutze2008introduction"><sup><a
href="#ref-schutze2008introduction"
role="doc-biblioref">6</a></sup></span></li>
<li>Bayesian Reasoning and Machine Learning<span class="citation"
data-cites="barber2012bayesian"><sup><a href="#ref-barber2012bayesian"
role="doc-biblioref">9</a></sup></span></li>
<li>Neural Networks and Deep Learning<span class="citation"
data-cites="nielsen2015neural"><sup><a href="#ref-nielsen2015neural"
role="doc-biblioref">19</a></sup></span></li>
<li>Deep Learning<span class="citation"
data-cites="goodfellow2016deep"><sup><a href="#ref-goodfellow2016deep"
role="doc-biblioref">23</a></sup></span></li>
<li>Foundations of Machine Learning<span class="citation"
data-cites="mohri2018foundations"><sup><a
href="#ref-mohri2018foundations"
role="doc-biblioref">29</a></sup></span></li>
<li><em>Reinforcement Learning: An Introduction</em><span
class="citation" data-cites="andrew2018reinforcement"><sup><a
href="#ref-andrew2018reinforcement"
role="doc-biblioref">30</a></sup></span></li>
<li>Grokking Machine Learning<span class="citation"
data-cites="serrano2021grokking"><sup><a href="#ref-serrano2021grokking"
role="doc-biblioref">50</a></sup></span></li>
<li>Deep Learning from Scratch: Building with Python from First
Principles<span class="citation" data-cites="weidman2019deep"><sup><a
href="#ref-weidman2019deep"
role="doc-biblioref">35</a></sup></span></li>
<li>The Hundred-Page Machine Learning Book<span class="citation"
data-cites="burkov2019hundred"><sup><a href="#ref-burkov2019hundred"
role="doc-biblioref">36</a></sup></span></li>
<li><em>Artificial Intelligence: A Modern Approach</em><span
class="citation" data-cites="russell2020artificial"><sup><a
href="#ref-russell2020artificial"
role="doc-biblioref">40</a></sup></span></li>
<li>Neural Networks from Scratch in Python: Building Neural Networks in
Raw Python<span class="citation" data-cites="kinsley2020neural"><sup><a
href="#ref-kinsley2020neural"
role="doc-biblioref">41</a></sup></span></li>
<li>Deep Learning for Coders with Fastai and PyTorch: AI Applications
Without a PhD<span class="citation" data-cites="howard2020deep"><sup><a
href="#ref-howard2020deep" role="doc-biblioref">42</a></sup></span></li>
<li><em>Mathematics for Machine Learning</em><span class="citation"
data-cites="deisenroth2020mathematics"><sup><a
href="#ref-deisenroth2020mathematics"
role="doc-biblioref">43</a></sup></span></li>
<li>Introduction to Machine Learning<span class="citation"
data-cites="alpaydin2020introduction"><sup><a
href="#ref-alpaydin2020introduction"
role="doc-biblioref">44</a></sup></span></li>
<li>Deep Learning with Python<span class="citation"
data-cites="chollet2021deep"><sup><a href="#ref-chollet2021deep"
role="doc-biblioref">49</a></sup></span></li>
<li>Programming Massively Parallel Processors: A Hands-on Approach<span
class="citation" data-cites="kirk2016programming"><sup><a
href="#ref-kirk2016programming"
role="doc-biblioref">52</a></sup></span></li>
<li>Designing Machine Learning Systems<span class="citation"
data-cites="huyen2022designing"><sup><a href="#ref-huyen2022designing"
role="doc-biblioref">53</a></sup></span></li>
<li>Machine Learning with PyTorch and Scikit-Learn: Develop Machine
Learning and Deep Learning Models with Python<span class="citation"
data-cites="raschka2022machine"><sup><a href="#ref-raschka2022machine"
role="doc-biblioref">54</a></sup></span></li>
<li>Probabilistic Machine Learning: An Introduction<span
class="citation" data-cites="murphy2022probabilistic"><sup><a
href="#ref-murphy2022probabilistic"
role="doc-biblioref">55</a></sup></span></li>
<li>The Principles of Deep Learning Theory<span class="citation"
data-cites="roberts2022principles"><sup><a
href="#ref-roberts2022principles"
role="doc-biblioref">56</a></sup></span></li>
<li>Understanding Deep Learning<span class="citation"
data-cites="prince2023understanding"><sup><a
href="#ref-prince2023understanding"
role="doc-biblioref">57</a></sup></span></li>
<li><em>An Introduction to Statistical Learning: With Applications in
Python</em><span class="citation"
data-cites="james2023introduction"><sup><a
href="#ref-james2023introduction"
role="doc-biblioref">58</a></sup></span></li>
<li>The Little Book of Deep Learning<span class="citation"
data-cites="fleuret2023little"><sup><a href="#ref-fleuret2023little"
role="doc-biblioref">59</a></sup></span></li>
<li>Dive into Deep Learning<span class="citation"
data-cites="zhang2023dive"><sup><a href="#ref-zhang2023dive"
role="doc-biblioref">60</a></sup></span></li>
<li><em>Deep Learning: Foundations and Concepts</em><span
class="citation" data-cites="bishop2024deep"><sup><a
href="#ref-bishop2024deep" role="doc-biblioref">64</a></sup></span></li>
<li>Multi-agent Reinforcement Learning: Foundations and Modern
Approaches<span class="citation" data-cites="albrecht2024multi"><sup><a
href="#ref-albrecht2024multi"
role="doc-biblioref">65</a></sup></span></li>
<li>Introduction to AI Safety, Ethics and Society<span class="citation"
data-cites="hendrycks2024introduction"><sup><a
href="#ref-hendrycks2024introduction"
role="doc-biblioref">66</a></sup></span></li>
<li><em>AI Engineering: Building Applications with Foundation
Models</em><span class="citation" data-cites="aiebook2025"><sup><a
href="#ref-aiebook2025" role="doc-biblioref">68</a></sup></span></li>
</ol>
<h2 id="code">Code</h2>
<ul>
<li><a href="https://github.com/python/cpython">Python</a> &amp; <a
href="https://github.com/pytorch/pytorch">PyTorch</a> by Meta, <a
href="https://github.com/pytorch/xla">XLA</a> by Google</li>
<li><a href="https://github.com/jax-ml/jax">JAX</a> by Google
DeepMind<span class="citation" data-cites="jax2018github"><sup><a
href="#ref-jax2018github" role="doc-biblioref">32</a></sup></span></li>
<li><a href="https://github.com/tinygrad/tinygrad">tinygrad</a> by
George Hotz &amp; <a href="https://tinygrad.org">tiny corp</a></li>
<li><a href="https://github.com/huggingface">Hugging Face</a></li>
<li><a
href="https://github.com/lucidrains/x-transformers">x-transfomers</a> by
Phil Wang (aka lucidrains)</li>
<li><a href="https://github.com/ml-explore/mlx">MLX</a><span
class="citation" data-cites="mlx2023"><sup><a href="#ref-mlx2023"
role="doc-biblioref">62</a></sup></span>, <a
href="https://github.com/ml-explore/mlx-examples">MLX examples</a> &amp;
<a href="https://github.com/apple/axlearn">axlearn</a> by Apple</li>
<li><a href="https://github.com/ggerganov/ggml">ggml</a> by Georgi
Gerganov</li>
<li><a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>, <a
href="https://github.com/karpathy/micrograd">micrograd</a>, &amp; <a
href="https://github.com/karpathy/llm.c">llm.c</a> by Andrej
Karpathy</li>
<li><a href="https://github.com/triton-lang/triton">Triton</a> by
OpenAI<span class="citation" data-cites="tillet2019triton"><sup><a
href="#ref-tillet2019triton"
role="doc-biblioref">38</a></sup></span></li>
<li><a href="https://github.com/NVIDIA/cuda-samples">CUDA</a> by Nvidia
&amp; <a href="https://github.com/srush/GPU-Puzzles">GPU Puzzles</a> by
Sasha Rush</li>
</ul>
<h2 id="papers">Papers</h2>
<ol type="1">
<li>First Law of Complexodynamics<span class="citation"
data-cites="aaronson2014quantifying"><sup><a
href="#ref-aaronson2014quantifying"
role="doc-biblioref">11</a></sup></span></li>
<li>Minimum Description Length Principle<span class="citation"
data-cites="hinton1993keeping"><sup><a href="#ref-hinton1993keeping"
role="doc-biblioref">2</a></sup></span></li>
<li>Kolmogorov Complexity<span class="citation"
data-cites="shen2022kolmogorov"><sup><a href="#ref-shen2022kolmogorov"
role="doc-biblioref">51</a></sup></span></li>
<li>Recurrent Neural Networks (RNNs)<span class="citation"
data-cites="karpathy2015unreasonable"><sup><a
href="#ref-karpathy2015unreasonable"
role="doc-biblioref">15</a></sup></span></li>
<li>Long Short-Term Memory (LSTM)<span class="citation"
data-cites="olah2015understanding"><sup><a
href="#ref-olah2015understanding"
role="doc-biblioref">16</a></sup></span></li>
<li>Convolutional Neural Networks (CNNs)<span class="citation"
data-cites="krizhevsky2012imagenet fei2024cs231n"><sup><a
href="#ref-krizhevsky2012imagenet" role="doc-biblioref">8</a>,<a
href="#ref-fei2024cs231n" role="doc-biblioref">63</a></sup></span></li>
<li>Transformers<span class="citation"
data-cites="vaswani2017attention rush2018annotated"><sup><a
href="#ref-vaswani2017attention" role="doc-biblioref">24</a>,<a
href="#ref-rush2018annotated"
role="doc-biblioref">27</a></sup></span></li>
<li>Residual Networks<span class="citation"
data-cites="amodei2016deep he2016identity"><sup><a
href="#ref-he2016identity" role="doc-biblioref">20</a>,<a
href="#ref-amodei2016deep" role="doc-biblioref">22</a></sup></span></li>
<li>Neural Turing Machines<span class="citation"
data-cites="graves2014neural"><sup><a href="#ref-graves2014neural"
role="doc-biblioref">12</a></sup></span></li>
<li>Pointer Networks<span class="citation"
data-cites="vinyals2015pointer"><sup><a href="#ref-vinyals2015pointer"
role="doc-biblioref">17</a></sup></span></li>
<li>Multi-scale context aggregation (dilated convolutions)<span
class="citation" data-cites="yu2015multi"><sup><a
href="#ref-yu2015multi" role="doc-biblioref">18</a></sup></span></li>
<li>Joint learning of alignment and translation in NMT<span
class="citation" data-cites="bahdanau2014neural"><sup><a
href="#ref-bahdanau2014neural"
role="doc-biblioref">10</a></sup></span></li>
<li>Variational lossy autoencoders<span class="citation"
data-cites="chen2016variational"><sup><a href="#ref-chen2016variational"
role="doc-biblioref">21</a></sup></span></li>
<li>RNN regularization techniques<span class="citation"
data-cites="zaremba2014recurrent"><sup><a
href="#ref-zaremba2014recurrent"
role="doc-biblioref">13</a></sup></span></li>
<li>Minimizing description length of neural network weights<span
class="citation" data-cites="hinton1993keeping"><sup><a
href="#ref-hinton1993keeping"
role="doc-biblioref">2</a></sup></span></li>
<li>GPipe: Efficient training of giant neural networks<span
class="citation" data-cites="huang2019gpipe"><sup><a
href="#ref-huang2019gpipe" role="doc-biblioref">33</a></sup></span></li>
<li>Scaling laws for neural language models<span class="citation"
data-cites="kaplan2020scaling"><sup><a href="#ref-kaplan2020scaling"
role="doc-biblioref">39</a></sup></span></li>
<li>Neural message passing for quantum chemistry<span class="citation"
data-cites="gilmer2017neural"><sup><a href="#ref-gilmer2017neural"
role="doc-biblioref">26</a></sup></span></li>
<li>Deep Speech 2 for end-to-end speech recognition<span
class="citation" data-cites="amodei2016deep"><sup><a
href="#ref-amodei2016deep" role="doc-biblioref">22</a></sup></span></li>
<li>Relational reasoning modules<span class="citation"
data-cites="santoro2017simple"><sup><a href="#ref-santoro2017simple"
role="doc-biblioref">25</a></sup></span></li>
<li>Relational RNNs<span class="citation"
data-cites="santoro2018relational"><sup><a
href="#ref-santoro2018relational"
role="doc-biblioref">28</a></sup></span></li>
<li>Quantifying complexity in closed systems<span class="citation"
data-cites="aaronson2014quantifying"><sup><a
href="#ref-aaronson2014quantifying"
role="doc-biblioref">11</a></sup></span></li>
<li>Machine Super Intelligence<span class="citation"
data-cites="legg2008machine"><sup><a href="#ref-legg2008machine"
role="doc-biblioref">5</a></sup></span></li>
<li>Identity mappings in deep residual networks<span class="citation"
data-cites="he2016identity"><sup><a href="#ref-he2016identity"
role="doc-biblioref">20</a></sup></span></li>
<li>Sequence-to-sequence models for sets<span class="citation"
data-cites="vinyals2015pointer"><sup><a href="#ref-vinyals2015pointer"
role="doc-biblioref">17</a></sup></span></li>
<li>Attention Is All You Need<span class="citation"
data-cites="vaswani2017attention"><sup><a
href="#ref-vaswani2017attention"
role="doc-biblioref">24</a></sup></span></li>
<li>CS231n Deep Learning for Computer Vision<span class="citation"
data-cites="fei2024cs231n"><sup><a href="#ref-fei2024cs231n"
role="doc-biblioref">63</a></sup></span></li>
</ol>
<h2 class="unnumbered" id="references">References</h2>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0"
data-line-spacing="2" role="list">
<div id="ref-clarke2013profiles" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div
class="csl-right-inline">Clarke, A. C. <em>Profiles of the future</em>.
(Hachette UK, 1962).</div>
</div>
<div id="ref-hinton1993keeping" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div
class="csl-right-inline">Hinton, G. E. &amp; Van Camp, D. <a
href="https://www.cs.toronto.edu/~hinton/absps/colt93.pdf">Keeping the
neural networks simple by minimizing the description length of the
weights</a>. in <em>Proceedings of the sixth annual conference on
computational learning theory</em> 5–13 (1993).</div>
</div>
<div id="ref-hamming1997art" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div
class="csl-right-inline">Hamming, R. R. <em>Art of doing science and
engineering: Learning to learn</em>. 432 (CRC Press, 1997).</div>
</div>
<div id="ref-petzold2000code" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div
class="csl-right-inline">Petzold, C. <em>Code: The hidden language of
computer hardware and software</em>. (Microsoft Press, 2000).</div>
</div>
<div id="ref-legg2008machine" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div
class="csl-right-inline">Legg, S. <a
href="https://www.vetta.org/documents/Machine_Super_Intelligence.pdf">Machine
super intelligence</a>. (2008).</div>
</div>
<div id="ref-schutze2008introduction" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div
class="csl-right-inline">Schütze, H., Manning, C. D. &amp; Raghavan, P.
<em><a
href="https://nlp.stanford.edu/IR-book/information-retrieval-book.html">Introduction
to information retrieval</a></em>. <strong>39,</strong> 506 (Cambridge
University Press Cambridge, 2008).</div>
</div>
<div id="ref-scott2009but" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div
class="csl-right-inline">Scott, J. C. <em>But how do it know?: The basic
principles of computers for everyone</em>. (John C Scott, 2009).</div>
</div>
<div id="ref-krizhevsky2012imagenet" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div
class="csl-right-inline">Krizhevsky, A., Sutskever, I. &amp; Hinton, G.
E. <a
href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">Imagenet
classification with deep convolutional neural networks</a>. <em>Advances
in neural information processing systems</em> <strong>25,</strong>
(2012).</div>
</div>
<div id="ref-barber2012bayesian" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div
class="csl-right-inline">Barber, D. <em><a
href="http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/020217.pdf">Bayesian
reasoning and machine learning</a></em>. (Cambridge University Press,
2012).</div>
</div>
<div id="ref-bahdanau2014neural" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div
class="csl-right-inline">Bahdanau, D., Cho, K. &amp; Bengio, Y. <a
href="https://arxiv.org/pdf/1409.0473.pdf">Neural machine translation by
jointly learning to align and translate</a>. <em>arXiv preprint
arXiv:1409.0473</em> (2014).</div>
</div>
<div id="ref-aaronson2014quantifying" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div
class="csl-right-inline">Aaronson, S., Carroll, S. M. &amp; Ouellette,
L. <a href="https://arxiv.org/pdf/1405.6903.pdf">Quantifying the rise
and fall of complexity in closed systems: The coffee automaton</a>.
<em>arXiv preprint arXiv:1405.6903</em> (2014).</div>
</div>
<div id="ref-graves2014neural" class="csl-entry" role="listitem">
<div class="csl-left-margin">12. </div><div
class="csl-right-inline">Graves, A., Wayne, G. &amp; Danihelka, I. <a
href="https://arxiv.org/pdf/1410.5401.pdf">Neural turing machines</a>.
<em>arXiv preprint arXiv:1410.5401</em> (2014).</div>
</div>
<div id="ref-zaremba2014recurrent" class="csl-entry" role="listitem">
<div class="csl-left-margin">13. </div><div
class="csl-right-inline">Zaremba, W., Sutskever, I. &amp; Vinyals, O. <a
href="https://arxiv.org/pdf/1409.2329.pdf">Recurrent neural network
regularization</a>. <em>arXiv preprint arXiv:1409.2329</em>
(2014).</div>
</div>
<div id="ref-bostrom2014paths" class="csl-entry" role="listitem">
<div class="csl-left-margin">14. </div><div
class="csl-right-inline">Bostrom, N. S. <em>Paths, dangers,
strategies</em>. (Oxford University Press: Oxford, UK, 2014).</div>
</div>
<div id="ref-karpathy2015unreasonable" class="csl-entry"
role="listitem">
<div class="csl-left-margin">15. </div><div
class="csl-right-inline">Karpathy, A. <a
href="https://karpathy.github.io/2015/05/21/rnn-effectiveness">The
unreasonable effectiveness of RNNs</a>. (2015).</div>
</div>
<div id="ref-olah2015understanding" class="csl-entry" role="listitem">
<div class="csl-left-margin">16. </div><div
class="csl-right-inline">Olah, C. <a
href="https://colah.github.io/posts/2015-08-Understanding-LSTMs">Understanding
LSTM networks</a>. (2015).</div>
</div>
<div id="ref-vinyals2015pointer" class="csl-entry" role="listitem">
<div class="csl-left-margin">17. </div><div
class="csl-right-inline">Vinyals, O., Fortunato, M. &amp; Jaitly, N. <a
href="https://arxiv.org/pdf/1506.03134.pdf">Pointer networks</a>.
<em>Advances in neural information processing systems</em>
<strong>28,</strong> (2015).</div>
</div>
<div id="ref-yu2015multi" class="csl-entry" role="listitem">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Yu,
F. &amp; Koltun, V. <a
href="https://arxiv.org/pdf/1511.07122.pdf">Multi-scale context
aggregation by dilated convolutions</a>. <em>arXiv preprint
arXiv:1511.07122</em> (2015).</div>
</div>
<div id="ref-nielsen2015neural" class="csl-entry" role="listitem">
<div class="csl-left-margin">19. </div><div
class="csl-right-inline">Nielsen, A. <a
href="https://lit2talks.com/upload/neuralnetworksanddeeplearning.pdf">Neural
networks and deep learning</a>. (2015).</div>
</div>
<div id="ref-he2016identity" class="csl-entry" role="listitem">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">He,
K., Zhang, X., Ren, S. &amp; Sun, J. <a
href="https://arxiv.org/pdf/1603.05027.pdf">Identity mappings in deep
residual networks</a>. in <em>Computer vision–ECCV 2016: 14th european
conference, amsterdam, the netherlands, october 11–14, 2016,
proceedings, part IV 14</em> 630–645 (Springer, 2016).</div>
</div>
<div id="ref-chen2016variational" class="csl-entry" role="listitem">
<div class="csl-left-margin">21. </div><div
class="csl-right-inline">Chen, X. <em>et al.</em> <a
href="https://arxiv.org/pdf/1611.02731.pdf">Variational lossy
autoencoder</a>. <em>arXiv preprint arXiv:1611.02731</em> (2016).</div>
</div>
<div id="ref-amodei2016deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">22. </div><div
class="csl-right-inline">Amodei, D. <em>et al.</em> <a
href="https://arxiv.org/pdf/1512.02595.pdf">Deep speech 2: End-to-end
speech recognition in english and mandarin</a>. in <em>International
conference on machine learning</em> 173–182 (PMLR, 2016).</div>
</div>
<div id="ref-goodfellow2016deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">23. </div><div
class="csl-right-inline">Goodfellow, I., Bengio, Y. &amp; Courville, A.
<em><a
href="https://annas-archive.org/md5/147862ee2c14791ac71520dca611a7d5">Deep
learning</a></em>. (MIT press, 2016).</div>
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
<div class="csl-left-margin">24. </div><div
class="csl-right-inline">Vaswani, A. <em>et al.</em> <a
href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention
is all you need</a>. <em>Advances in neural information processing
systems</em> <strong>30,</strong> (2017).</div>
</div>
<div id="ref-santoro2017simple" class="csl-entry" role="listitem">
<div class="csl-left-margin">25. </div><div
class="csl-right-inline">Santoro, A. <em>et al.</em> <a
href="https://proceedings.neurips.cc/paper_files/paper/2017/file/e6acf4b0f69f6f6e60e9a815938aa1ff-Paper.pdf">A
simple neural network module for relational reasoning</a>. <em>Advances
in neural information processing systems</em> <strong>30,</strong>
(2017).</div>
</div>
<div id="ref-gilmer2017neural" class="csl-entry" role="listitem">
<div class="csl-left-margin">26. </div><div
class="csl-right-inline">Gilmer, J., Schoenholz, S. S., Riley, P. F.,
Vinyals, O. &amp; Dahl, G. E. <a
href="https://arxiv.org/pdf/1704.01212">Neural message passing for
quantum chemistry</a>. in <em>International conference on machine
learning</em> 1263–1272 (PMLR, 2017).</div>
</div>
<div id="ref-rush2018annotated" class="csl-entry" role="listitem">
<div class="csl-left-margin">27. </div><div
class="csl-right-inline">Rush, A. M. <a
href="https://nlp.seas.harvard.edu/annotated-transformer/">The annotated
transformer</a>. in <em>Proceedings of workshop for NLP open source
software (NLP-OSS)</em> 52–60 (2018).</div>
</div>
<div id="ref-santoro2018relational" class="csl-entry" role="listitem">
<div class="csl-left-margin">28. </div><div
class="csl-right-inline">Santoro, A. <em>et al.</em> <a
href="https://proceedings.neurips.cc/paper_files/paper/2018/file/e2eabaf96372e20a9e3d4b5f83723a61-Paper.pdf">Relational
recurrent neural networks</a>. <em>Advances in neural information
processing systems</em> <strong>31,</strong> (2018).</div>
</div>
<div id="ref-mohri2018foundations" class="csl-entry" role="listitem">
<div class="csl-left-margin">29. </div><div
class="csl-right-inline">Mohri, M., Rostamizadeh, A. &amp; Talwalkar, A.
<em><a
href="https://annas-archive.org/md5/1495446fc912817f0cd2986905eb8389">Foundations
of machine learning</a></em>. (MIT press, 2018).</div>
</div>
<div id="ref-andrew2018reinforcement" class="csl-entry" role="listitem">
<div class="csl-left-margin">30. </div><div
class="csl-right-inline">Andrew, B. &amp; Richard S, S. <a
href="https://annas-archive.org/md5/cd556761e796b7c76c1c7a570482eba7">Reinforcement
learning: An introduction</a>. (2018).</div>
</div>
<div id="ref-tegmark2018life" class="csl-entry" role="listitem">
<div class="csl-left-margin">31. </div><div
class="csl-right-inline">Tegmark, M. <em>Life 3.0: Being human in the
age of artificial intelligence</em>. (Vintage, 2018).</div>
</div>
<div id="ref-jax2018github" class="csl-entry" role="listitem">
<div class="csl-left-margin">32. </div><div
class="csl-right-inline">Bradbury, J. <em>et al.</em> <a
href="http://github.com/jax-ml/jax"><span>JAX</span>: Composable
transformations of <span>P</span>ython+<span>N</span>um<span>P</span>y
programs</a>. (2018).</div>
</div>
<div id="ref-huang2019gpipe" class="csl-entry" role="listitem">
<div class="csl-left-margin">33. </div><div
class="csl-right-inline">Huang, Y. <em>et al.</em> <a
href="https://proceedings.neurips.cc/paper_files/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf">Gpipe:
Efficient training of giant neural networks using pipeline
parallelism</a>. <em>Advances in neural information processing
systems</em> <strong>32,</strong> (2019).</div>
</div>
<div id="ref-russell2019human" class="csl-entry" role="listitem">
<div class="csl-left-margin">34. </div><div
class="csl-right-inline">Russell, S. <em>Human compatible: AI and the
problem of control</em>. (Penguin Uk, 2019).</div>
</div>
<div id="ref-weidman2019deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">35. </div><div
class="csl-right-inline">Weidman, S. <em><a
href="https://annas-archive.org/md5/af1400a89b34bf0ac0a4a35d108d67ad">Deep
learning from scratch: Building with python from first
principles</a></em>. (O’Reilly Media, 2019).</div>
</div>
<div id="ref-burkov2019hundred" class="csl-entry" role="listitem">
<div class="csl-left-margin">36. </div><div
class="csl-right-inline">Burkov, A. <em><a
href="https://annas-archive.org/md5/07912d7f54c6ef124c53d18cc69859bf">The
hundred-page machine learning book</a></em>. (Andriy Burkov Quebec City,
QC, Canada, 2019).</div>
</div>
<div id="ref-pickover2019artificial" class="csl-entry" role="listitem">
<div class="csl-left-margin">37. </div><div
class="csl-right-inline">Pickover, C. A. <em>Artificial intelligence:
From medieval robots to neural networks</em>. (Union Square+ ORM,
2019).</div>
</div>
<div id="ref-tillet2019triton" class="csl-entry" role="listitem">
<div class="csl-left-margin">38. </div><div
class="csl-right-inline">Tillet, P., Kung, H.-T. &amp; Cox, D. <a
href="https://www.eecs.harvard.edu/~htk/publication/2019-mapl-tillet-kung-cox.pdf">Triton:
An intermediate language and compiler for tiled neural network
computations</a>. 10–19 (2019).</div>
</div>
<div id="ref-kaplan2020scaling" class="csl-entry" role="listitem">
<div class="csl-left-margin">39. </div><div
class="csl-right-inline">Kaplan, J. <em>et al.</em> <a
href="https://arxiv.org/pdf/2001.08361">Scaling laws for neural language
models</a>. <em>arXiv preprint arXiv:2001.08361</em> (2020).</div>
</div>
<div id="ref-russell2020artificial" class="csl-entry" role="listitem">
<div class="csl-left-margin">40. </div><div
class="csl-right-inline">Russell, S. J. &amp; Norvig, P. <em>Artificial
intelligence: A modern approach</em>. (Pearson, 2020).</div>
</div>
<div id="ref-kinsley2020neural" class="csl-entry" role="listitem">
<div class="csl-left-margin">41. </div><div
class="csl-right-inline">Kinsley, H. &amp; Kukieła, D. <em>Neural
networks from scratch in python: Building neural networks in raw
python</em>. (Verlag nicht ermittelbar, 2020).</div>
</div>
<div id="ref-howard2020deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">42. </div><div
class="csl-right-inline">Howard, J. &amp; Gugger, S. <em><a
href="https://annas-archive.org/md5/7e55aada5f4f30daa2a340c5409c896c">Deep
learning for coders with fastai and PyTorch</a></em>. (O’Reilly Media,
2020).</div>
</div>
<div id="ref-deisenroth2020mathematics" class="csl-entry"
role="listitem">
<div class="csl-left-margin">43. </div><div
class="csl-right-inline">Deisenroth, M. P., Faisal, A. A. &amp; Ong, C.
S. <em><a
href="https://annas-archive.org/md5/170355f6bd92c95c84a43414cfcffec2">Mathematics
for machine learning</a></em>. (Cambridge University Press, 2020).</div>
</div>
<div id="ref-alpaydin2020introduction" class="csl-entry"
role="listitem">
<div class="csl-left-margin">44. </div><div
class="csl-right-inline">Alpaydin, E. <em><a
href="https://annas-archive.org/md5/4e078be579f512b629817cbc83b62e93">Introduction
to machine learning</a></em>. (MIT press, 2020).</div>
</div>
<div id="ref-dehaene2021we" class="csl-entry" role="listitem">
<div class="csl-left-margin">45. </div><div
class="csl-right-inline">Dehaene, S. <em>How we learn: Why brains learn
better than any machine... For now</em>. (Penguin, 2021).</div>
</div>
<div id="ref-haigh2021new" class="csl-entry" role="listitem">
<div class="csl-left-margin">46. </div><div
class="csl-right-inline">Haigh, T. &amp; Ceruzzi, P. E. <em>A new
history of modern computing</em>. (MIT Press, 2021).</div>
</div>
<div id="ref-christian2021alignment" class="csl-entry" role="listitem">
<div class="csl-left-margin">47. </div><div
class="csl-right-inline">Christian, B. <em>The alignment problem: How
can machines learn human values?</em> (Atlantic Books, 2021).</div>
</div>
<div id="ref-nisan2021elements" class="csl-entry" role="listitem">
<div class="csl-left-margin">48. </div><div
class="csl-right-inline">Nisan, N. &amp; Schocken, S. <em>The elements
of computing systems: Building a modern computer from first
principles</em>. (MIT press, 2021).</div>
</div>
<div id="ref-chollet2021deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">49. </div><div
class="csl-right-inline">Chollet, F. <em><a
href="https://annas-archive.org/md5/59737ebea569c42afd3c3acabf2a5f9a">Deep
learning with python</a></em>. (Simon; Schuster, 2021).</div>
</div>
<div id="ref-serrano2021grokking" class="csl-entry" role="listitem">
<div class="csl-left-margin">50. </div><div
class="csl-right-inline">Serrano, L. <em>Grokking machine learning</em>.
(Simon; Schuster, 2021).</div>
</div>
<div id="ref-shen2022kolmogorov" class="csl-entry" role="listitem">
<div class="csl-left-margin">51. </div><div
class="csl-right-inline">Shen, A., Uspensky, V. A. &amp; Vereshchagin,
N. <em><a
href="https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf">Kolmogorov
complexity and algorithmic randomness</a></em>. <strong>220,</strong>
434–497 (American Mathematical Society, 2022).</div>
</div>
<div id="ref-kirk2016programming" class="csl-entry" role="listitem">
<div class="csl-left-margin">52. </div><div
class="csl-right-inline">Kirk, D. B. &amp; Wen-Mei, W. H.
<em>Programming massively parallel processors: A hands-on approach</em>.
(2022).</div>
</div>
<div id="ref-huyen2022designing" class="csl-entry" role="listitem">
<div class="csl-left-margin">53. </div><div
class="csl-right-inline">Huyen, C. <em><a
href="https://annas-archive.org/md5/f5c999ff6f4f7def83fa044b038f9390">Designing
machine learning systems</a></em>. (" O’Reilly Media, Inc.",
2022).</div>
</div>
<div id="ref-raschka2022machine" class="csl-entry" role="listitem">
<div class="csl-left-margin">54. </div><div
class="csl-right-inline">Raschka, S., Liu, Y. H., Mirjalili, V. &amp;
Dzhulgakov, D. <em><a
href="https://annas-archive.org/md5/c1ae0c9c5eaff8b929972790879197e6">Machine
learning with PyTorch and scikit-learn: Develop machine learning and
deep learning models with python</a></em>. (Packt Publishing Ltd,
2022).</div>
</div>
<div id="ref-murphy2022probabilistic" class="csl-entry" role="listitem">
<div class="csl-left-margin">55. </div><div
class="csl-right-inline">Murphy, K. P. <em><a
href="https://annas-archive.org/md5/9a26e8cc5fa4c0b40d7a91443f9b71f8">Probabilistic
machine learning: An introduction</a></em>. (MIT press, 2022).</div>
</div>
<div id="ref-roberts2022principles" class="csl-entry" role="listitem">
<div class="csl-left-margin">56. </div><div
class="csl-right-inline">Roberts, D. A., Yaida, S. &amp; Hanin, B.
<em><a
href="https://annas-archive.org/md5/e1fdfd303f45ed2689fe3c0dcfe1db62">The
principles of deep learning theory</a></em>. (Cambridge University Press
Cambridge, MA, USA, 2022).</div>
</div>
<div id="ref-prince2023understanding" class="csl-entry" role="listitem">
<div class="csl-left-margin">57. </div><div
class="csl-right-inline">Prince, S. J. D. <em><a
href="http://udlbook.com">Understanding deep learning</a></em>. (The MIT
Press, 2023).</div>
</div>
<div id="ref-james2023introduction" class="csl-entry" role="listitem">
<div class="csl-left-margin">58. </div><div
class="csl-right-inline">James, G., Witten, D., Hastie, T., Tibshirani,
R. &amp; Taylor, J. <em><a href="https://www.statlearning.com">An
introduction to statistical learning: With applications in
python</a></em>. (Springer Nature, 2023).</div>
</div>
<div id="ref-fleuret2023little" class="csl-entry" role="listitem">
<div class="csl-left-margin">59. </div><div
class="csl-right-inline">Fleuret, F. <em><a
href="https://fleuret.org/public/lbdl.pdf">The little book of deep
learning</a></em>. <em>A lovely concise introduction</em> 297
(2023).</div>
</div>
<div id="ref-zhang2023dive" class="csl-entry" role="listitem">
<div class="csl-left-margin">60. </div><div
class="csl-right-inline">Zhang, A., Lipton, Z. C., Li, M. &amp; Smola,
A. J. <em><a href="https://d2l.ai">Dive into deep learning</a></em>.
(Cambridge University Press, 2023).</div>
</div>
<div id="ref-li2023worlds" class="csl-entry" role="listitem">
<div class="csl-left-margin">61. </div><div class="csl-right-inline">Li,
F.-F. <em>The worlds i see: Curiosity, exploration, and discovery at the
dawn of AI</em>. (Flatiron books: a moment of lift book, 2023).</div>
</div>
<div id="ref-mlx2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">62. </div><div
class="csl-right-inline">Hannun, A., Digani, J., Katharopoulos, A. &amp;
Collobert, R. <a href="https://github.com/ml-explore"><span>MLX</span>:
Efficient and flexible machine learning on apple silicon</a>.
(2023).</div>
</div>
<div id="ref-fei2024cs231n" class="csl-entry" role="listitem">
<div class="csl-left-margin">63. </div><div
class="csl-right-inline">Fei-Fei, L., Karpathy, A. &amp; Johnson, J. <a
href="https://cs231n.github.io/">CS231n convolutional neural networks
for visual recognition</a>. <em>Stanford University</em> (2024).</div>
</div>
<div id="ref-bishop2024deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">64. </div><div
class="csl-right-inline">Bishop, C. M. &amp; Bishop, H. <em><a
href="https://annas-archive.org/md5/6d1f851e90bf7847ad9999efadc56d5b">Deep
learning: Foundations and concepts</a></em>. (Springer, 2024).</div>
</div>
<div id="ref-albrecht2024multi" class="csl-entry" role="listitem">
<div class="csl-left-margin">65. </div><div
class="csl-right-inline">Albrecht, S. V., Christianos, F. &amp; Schäfer,
L. <em>Multi-agent reinforcement learning: Foundations and modern
approaches</em>. (MIT Press, 2024).</div>
</div>
<div id="ref-hendrycks2024introduction" class="csl-entry"
role="listitem">
<div class="csl-left-margin">66. </div><div
class="csl-right-inline">Hendrycks, D. <em>Introduction to AI safety,
ethics and society</em>. (Dan Hendrycks, 2024).</div>
</div>
<div id="ref-kurzweil2024singularity" class="csl-entry" role="listitem">
<div class="csl-left-margin">67. </div><div
class="csl-right-inline">Kurzweil, R. <em>The singularity is nearer:
When we merge with AI</em>. (Random House, 2024).</div>
</div>
<div id="ref-aiebook2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">68. </div><div
class="csl-right-inline">Huyen, C. <em><span>AI Engineering</span></em>.
(O’Reilly Media, 2025).</div>
</div>
</div></div>
      </main>
      <div class="statusbar">
        <div class="statusbar-left">F1 Help | F2 Save | F10 Exit</div>
        <div class="statusbar-right">Press Alt+F to access menu</div>
      </div>
    </div>
  </body>
</html>
